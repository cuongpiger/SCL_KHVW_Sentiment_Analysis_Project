{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.0. Enviroment, editor (IDE), programming language & dependent packages\n",
    "* **OS**: Ubuntu 20.04 LTS\n",
    "* **Programming language**: Python 3.6.8\n",
    "* **Python's dependent packages**:\n",
    "  ```shell\n",
    "  pip3 install selenium==3.141.0\n",
    "  pip3 install emojis==0.6.0\n",
    "  pip3 install pyenchant==3.2.1\n",
    "  pip3 install numpy==1.19.5\n",
    "  pip3 install pandas==1.2.4\n",
    "  pip3 install requests==2.22.0\n",
    "  pip3 install scikit-learn==0.24.2\n",
    "  ```\n",
    "  _Một vài package khác có thể sẽ yêu cầu cài thêm trong quá trình install các package phía trên nên sẽ không liệt kê trong đây._\n",
    "* **Editor**: VS-Code _(recommend)_, Jupyter Notebook, Jupyter Lab,..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.1. Trình bày chủ đề, lý do chọn chủ đề, trang web lấy hoặc trang web là hạt giống\n",
    "* Trong thương mại điện tử, việc liên tục nâng cao chất lượng sản phẩm và dịch vụ để đáp ứng nhu cầu khách hàng nhằm nâng cao uy tín là công việc hàng đầu cua của các doanh nghiệp khi tham gia sàn thương mại điện tử.\n",
    "* Hệ thống hỗ trợ doanh nghiệp phân loại các phản hồi của khách hàng thành hai nhóm: **positive** [nhóm khách hàng tích cực], kí hiệu <scan style=\"color: green\">$\\oplus$</scan> và **negative** [nhóm khách hàng tiêu cực], kí hiệu <scan style=\"color: red\">$\\ominus$</scan> dựa trên dữ liệu đầu vào dưới dạng **text** [tài liệu văn bản].\n",
    "* Hệ thống được xây dựng dựa trên lịch sử những đánh giá của khách hàng đã có trước đó, dữ liệu được thu thập từ phần **comment** [bình luận] và **rating** [số sao (điểm) đánh giá cho sản phẩm] của khách hàng ở trang web thương mại điện tử từ một nhóm ngành nào đó.\n",
    "* Hệ thống giúp doanh nghiệp có thể biết được những phản hồi nhanh chóng của khách hàng về sản phẩm, dịch vụ của họ, điều này giúp cho doanh nghiệp có thể hiểu được tình hình kinh doanh, hiểu được ý kiến của khách hàng từ đó giúp doanh nghiệp cải thiện hơn trong dịch vụ, sản phẩm.\n",
    "* Ở đây, trang thương mại điện tử được dùng để crawl dữ liệu là [**Shopee Việt Nam**](https://shopee.vn/), dữ liệu được crawl về là những bình luận và đánh giá của khách hàng về các sản phẩm thuộc nhóm ngành thời trang."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.2. Mô tả thuật toán, cấu trúc mã nguồn, các thành phần hệ thống\n",
    "###### Mô tả thuật toán và các thành phần của hệ thống\n",
    "* Đối với quá trình data pre-processing sẽ dc trình bày chi tiết trong phần 1.6 và 1.7 ở file `01.pre-processing_references.ipynb`, ở đây ta chỉ tập trung vào cách ta crawl dữ liệu.\n",
    "* Shopee là một dynamic website, điều này có nghĩa các component của trang sẽ dc load lên \"khi có sự tương tác\" của người dùng, ta cứ hình dung như trang newfeeds của Facebook, ban đầu chỉ hiện một vài bài viết sau đó khi ta scroll để xem hết bài viết thì qua cơ chế AJAX nó sẽ load thêm các bài mới viết mới. Điều này giúp cho giảm tải về dung lượng mạng và thời gian waiting cho người dùng nhưng nó gián tiếp khiến cho việc crawl data khó thực hiện hơn.\n",
    "* Toán bộ thuật toán và chi tiết cách thực hiện nằm trong phần 1.2.1.\n",
    "###### Cấu trúc mã nguồn\n",
    "* Folder **modules** chứa các user defined function, class.\n",
    "* Folder **data** chứa các data mà ta crawl về, những data phát sinh sau bước pre-processing,...\n",
    "* Folder **images** chứa các hình minh họa.\n",
    "* File **00.intro_scraping.ipynb**: là các phần 1.1 đến 1.5 của báo cáo\n",
    "* File **01.pre-processing_references.ipynb**: chứa hai phần 1.6 và 1.7 của báo cáo.\n",
    "* File **modules/crawler.py**: định nghĩa các hàm dùng để crawl data\n",
    "* File **modules/processor.py**: định nghĩa các hàm dùng để tiền xử lí dữ liệu\n",
    "* File **modules/regex_patterns.py**: định nghĩa các regular expression để tiền xử lí dữ liệu\n",
    "* File **modules/user_object_defined.py**: định nghĩa các kiểu dữ liệu để tiện cho quá trình code, cho code clear và dễ hiểu\n",
    "* File **modules/utils.py**: chứa các hàm như đọc file txt, ghi file, các hàm chức năng,...\n",
    "* Folder **modules/dependencies**: chứa các file data dùng làm sạch dữ liệu, trong đó:\n",
    "  * **abbreviate.txt**: chứa các từ viết tắt và dạng chuẩn của từ viết tắt.\n",
    "  * **stopwords.txt**: các stopword tiếng việt\n",
    "  * **vocabulary.txt**: các từ đơn trong tiếng việt.\n",
    "## 1.2.1. Demo và chi tiết về cách thực hiện (khúc sau)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.3. Các vấn đề xảy ra đối với crawler và phương pháp xử lý\n",
    "* Đây là các vấn để trong crawler, các vấn để trong tiền xử lí sẽ được nói chi tiết trong mục 1.6 và 1.7.\n",
    "|Vấn đề|Phương pháp xử lí|\n",
    "|-|-|\n",
    "|Hầu hết các trang web thương mại điện tử hiện tại là dynamic website, chúng tiến hành load dữ liệu bằng AJAX. Và để crawl được dữ liệu từ các trang web như thế này thì đòi hỏi ta cần phải giả lập thao tác người dùng.|- Sử dụng **Selenium** để tiến hành giả lập thao tác người dùng.<br>- Các trang web thương mại điện tử ngày này có các API để hỗ trợ các lập trình viên có thể nhanh chóng crawl được dữ liệu.|\n",
    "|Vấn đề về đường truyền internet hiện tại đang bị hỏng khiến việc crawl data trở nên lâu và vất vả hơn|Chưa có biện pháp xử lí|"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.4. Các tính năng phức tạp của crawler\n",
    "* Giả lâp cuộn trang.\n",
    "* Cuộn trang và kiểm tra sự xuất hiện của một css selector dc chỉ định.\n",
    "* Giả lập click button\n",
    "* Crawl data bằng API\n",
    "* Linh hoạt trong thời gian timeout, thay vì ta sử dụng cơ chế là bắt crawler dừng tĩnh trong 3 giây, vậy nếu như ta đã access vào trang thành công trước 3 giây thì ta vẫn phải chờ cho hết 3 giây timeout. Cái ta muốn là tự động kết thúc timeout ngay khi ta truy cập vào trang thành công hoặc hết timeout 3 giây, lúc này ta sử dụng cơ chế `WebDriverWait(<browser driver>, <second waiting>).until()` của Selenium.\n",
    "* Kiểm tra đã kết thúc navigation hay chưa.\n",
    "* Các xử lí phức tạp trong tiền xử lí dữ liệu như regex, xử lí noise sample, extracting emoji sẽ dc trình bày chi tiết trong phần 1.6 và 1.7."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.5. Đánh giá hiệu năng crawler\n",
    "* Crawler nhìn chung hoạt động tốt, không bị hiện tương treo do cơ chế `WebDriverWait().until()` đã khắc phục điều này.\n",
    "* Tuy nhiên thời gian crawl lâu, mất từ 3 đến 5 ngày treo máy tính."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr>\n",
    "\n",
    "## 1.2.1. Demo và chi tiết về cách thực hiện\n",
    "* Khi truy cập vào trang chủ Shopee Việt Nam tại địa chỉ [https://shopee.vn](https://shopee.vn), khi kéo xuống một chút ta sẽ thấy được nhóm ngành thời trang như dưới đây:\n",
    "  ![](images/00.png)\n",
    "* Vùng red square là những nhóm hàng mà ta sẽ tập trung crawl cũng như xây dựng model về sau.\n",
    "* Một câu hỏi đặt ra là tại sao chúng ta không tạo ra một model mà nó có thể phân lớp cho toàn bộ tất cả các nhóm ngành trên trang thương mại điện tử này. Có một vài hạn chế như sau:\n",
    "  * Việc chúng ta có gắng nhồi nhét toàn bộ các comment của các nhóm ngành khác nhau và bắt máy tính phải học một đống này sẽ khiến cho quá trình học trở nên phức tạp, khó khăn và tốn thời gian, đồng thời nếu có xây dựng được model thì chất lượng nó cũng sẽ không tốt khi ta evaluate nó hoặc ứng dụng vào thực tế về sau.\n",
    "  * Các nhóm ngành khác nhau có những keyword khác nhau, ví dụ nhóm ngành thời trang sẽ có những keyword điển hình như: _vải xấu, áo mỏng, đổ lông,..._. Nhưng nếu trong nhóm ngành điện tử sẽ có những keyword như: _máy nóng, sạc không vô, chai pin,..._, nhưng giữa hai nhóm ngành thời trang và điện tử lại có những keyword chung như: _hàng không giống ảnh, giao sai màu, giao hàng chậm,..._ và điển hình ở các comment tích cực thì việc các keyword này overlap lên nhau thì càng nhiều hơn, ví dụ: _giao nhanh, sản phẩm tốt, chất lượng sản phẩm tuyệt vời,..._. Các comment tích cực hay có một xu hướng chung chung như vậy và không đề cập quá chi tiết về nhóm hàng mình đang đánh giá.\n",
    "  * Và nếu ta muốn một hệ thống có thể ứng dụng được trên toàn bộ hệ thống các nhóm hàng, thì lúc này ta có thể làm như sau:\n",
    "    * Giả sử ta là Shopee, thì ta biết rõ comment này thuộc sản phẩm nào và sản phẩm này thuộc nhóm hàng nào dựa vào các label, tag của sản phẩm, từ đó ta sẽ sử dụng model tương ứng cho nhóm hàng này để dự đoán.\n",
    "    * Nếu ta không là Shopee, ta có thể xây dựng thêm một model-1 với input là comment của khách hàng, output là nhóm hàng mà comment này khả năng cao thuộc về. Sau đó ta mới bắt đầu đưa comment này vào model-2 tương ứng với nhóm hàng mà model-1 đề xuất và đánh giá comment này.\n",
    "    Đây là một vài cách mà ta có thể ứng dụng. Thực tế thì các hệ thống này có khả năng cao phức tạp hơn nhiều, nhưng ở đây ta chỉ chú tâm vào nhóm hàng thời trang thôi. \n",
    "* Giả sử ta cần crawl data từ nhóm **Thời Trang Nam**, ta có thể click vào nó:<br>\n",
    "  ![](images/00.png)\n",
    "* Hãy chú ý vào các vùng khoanh đỏ trong hình dưới đây, ta thấy rằng trong URL có một thuộc tính là `page=0` và trong UI ta thấy nó đang là trang **1/100**. Vậy nếu ta thay giá trị `page` này từ **[0, 99]** thì ta có thể truy cập tương ứng vào các page từ **[1:100]**.<br>\n",
    "  ![](images/01.png)\n",
    "* Hãy thử right-click vào mặt hàng đầu tiên và chọn **inspect**, ta có thể thấy được các sản phẩm này được nằm trong một HTML tag element là:\n",
    "  ```html\n",
    "  <div class=\"col-xs-2-4 shopee-search-item-result__item\" data-sqe=\"item\">\n",
    "      ...\n",
    "  </div>\n",
    "  ```\n",
    "* Chúng ta thấy rằng các sản phẩm được bọc trong thẻ các tag `<div>` mà có class là `shopee-search-item-result__item`.<br>\n",
    "  ![](images/03.png)\n",
    "* Khi ta drop-down tag `<div>` này xuống, ta có thể thấy được tag `<a>` chứa hyper-link đến trang landing-page của sản phẩm này trong attribute `href`.<br>\n",
    "  ![](images/02.png)\n",
    "* Sơ bộ là vậy, bây giờ chúng ta sẽ tiến hành lấy tất cả các hypeylink dẫn đến các trang landing-page này."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Do quá trình crawl data là một quá trình đòi hỏi tốn nhiều thời gian, vì thế nên chỉ có thể tiến hành demo các bước nhỏ chứ không thể báo cáo toàn bộ quá trình crawl trên một paper được, điều này càng khó khả thi hơn khi crawl trên một dynamic website.\n",
    "* Bây giờ ta sẽ tiến hành lấy các URL của các sản phẩm để có thể truy cập vào trang riêng của sản phẩm đó."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import modules.crawler as Crawler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "product_urls = Crawler.getProductURLs(\"https://shopee.vn/Th%E1%BB%9Di-Trang-Nam-cat.11035567?page=\",\n",
    "                                      [0, 10], \"div.shopee-search-item-result__item > a\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "product_urls[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['https://shopee.vn/Qu%E1%BA%A7n-jogger-nam-kaki-NPV-ki%E1%BB%83u-d%C3%A1ng-th%E1%BB%83-thao-qu%E1%BA%A7n-d%C3%A0i-nam-ch%E1%BA%A5t-li%E1%BB%87u-kaki-co-gi%C3%A3n-4-m%C3%A0u-i.195541001.5928995027?position=480',\n",
       " 'https://shopee.vn/B%E1%BB%99-%C4%91%E1%BB%93ng-ph%E1%BB%A5c-th%E1%BB%83-thao-trung-h%E1%BB%8Dc-Fukurodani-h%C3%B3a-trang-nh%C3%A2n-v%E1%BA%ADt-Akaashi-Keiji-Bokuto-Koutarou-trong-anime-Haikyuu!!-i.254592742.7641350377?position=481',\n",
       " 'https://shopee.vn/Qu%E1%BA%A7n-Jogger-kaki-kho%C3%A1-k%C3%A9o-i.142208247.2904777654?position=482',\n",
       " 'https://shopee.vn/Qu%E1%BA%A7n-d%C3%A0i-nam-Qu%E1%BA%A7n-b%C3%B2-jean-%E1%BB%91ng-c%C3%B4n-Slim-H%C3%80NG-CAO-C%E1%BA%A4P-th%E1%BB%9Di-trang-phong-c%C3%A1ch-%C3%A2u-l%E1%BB%8Bch-l%C3%A3m-n%C4%83ng-%C4%91%E1%BB%99ng-KK3-i.89289068.6489798097?position=483',\n",
       " 'https://shopee.vn/Face-shield-k%C3%ADnh-ph%C3%B2ng-h%E1%BB%99-ch%E1%BB%91ng-gi%E1%BB%8Dt-b%E1%BA%AFn.-N%C3%B3n-Ch%E1%BB%91ng-D%E1%BB%8Bch-B%E1%BB%A5i-c%C3%B3-g%E1%BB%8Dng-cao-c%E1%BA%A5p-ph%C3%B9-h%E1%BB%A3p-m%E1%BB%8Di-l%E1%BB%A9a-tu%E1%BB%95i-i.25104965.7744121028?position=484']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.1.1. Crawl comment từ hai sản phẩm với URL mà ta đã bắt được từ bước trên bằng Selenium\n",
    "* Vậy tóm lại các bước thực hiện là như sau:\n",
    "  * Đầu tiên ta vào trang chủ, có thể search mặt hàng mà ta muốn crawl hoặc chọn các gợi ý có sẵn, copy đường dẫn về.\n",
    "  * Tiếp theo, với mỗi URL như vậy, mặc định sẽ có 100 trang, ta sẽ crawl về mọi URL của các sản phẩm từ 100 trang này.\n",
    "  * Vào URL của từng sản phẩm:\n",
    "    * Đi qua từng review navigation và crawl về toàn bộ.\n",
    "    * Nhấn nút next navigation page và quay lại bước trên\n",
    "      * Nếu unable clicking, thì đã hết review và dừng lại quá trình crawl"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "product_urls = [\n",
    "    \"https://shopee.vn/-M605-SET-B%E1%BB%98-TRANG-PH%E1%BB%A4C-L%E1%BB%8ACH-S%E1%BB%B0-SANG-TR%E1%BB%8CNG-CHO-NG%C6%AF%E1%BB%9CI-TRUNG-NI%C3%8AN-%C3%81O-VOAN-QU%E1%BA%A6N-C%C3%81T-H%C3%80N-THO%C3%81NG-M%C3%81T-CHO-M%C3%99A-H%C3%88-HOT-2021-i.443480495.9456560182?ads_keyword=a%CC%81o&adsid=14143076&campaignid=7782287&position=3\",\n",
    "    \"https://shopee.vn/B%E1%BB%99-Qu%E1%BA%A7n-%C3%81o-Nam-Tay-Ng%E1%BA%AFn-C%E1%BB%95-B%E1%BA%BB-%C3%81o-Khuy-C%C3%A0i-Qu%E1%BA%A7n-Short-C%C3%B3-T%C3%BAi-Ki%E1%BB%83u-D%C3%A1ng-Tr%E1%BA%BB-Trung-Th%E1%BB%9Di-Trang-Zenkonu_QANAM1000071V1-i.16580482.9540615863?position=8\"\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "product_reviews = [] # chứa các Review object\n",
    "\n",
    "for idx, product_url in enumerate(product_urls): # đi qua từng URL của sản phẩm\n",
    "    new_reviews = Crawler.getProductReviews(product_url) # lấy tất cả review của sản phẩm này\n",
    "    Crawler.writeToCsv(f\"./tmp/product_reviews_00/product_{idx}.csv\", new_reviews) # ghi mọi review của sản phẩm này ra file\n",
    "    \n",
    "    product_reviews += new_reviews # thêm vào để in kết quả (bước này kiểm tra cho cell dưới, thực tế ko sài)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "for review in product_reviews[:10]:\n",
    "    print(f\"{review.irating} - {review.icomment}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5 - Áo siêu mát luônnn í,chất đẹp lắm mua cho bà mà ưnggg hết sứcccc!!!!!!!Nên mua nhé mọi người rất hợp với ng già hoặc mua cho mẹ cũng hợp luôn😍\n",
      "5 - Đồ đẹp sang vải mát mịn nhé mẹ mình khen đẹp nhìn trẻ hẳn ra giao hàng cũng nhanh\n",
      "5 - Shop giao hàng rất nhanh và tư vấn rất nhiệt tình. Nhận đc hàng mình thấy khá ưng ý.\n",
      "Clip chỉ mang tính nhận xu ạ\n",
      "5 - Chất mát, nhẹ, mềm mịn mặc lên cảm giác siêu nhẹ mà mát lắm lắm luôn 👍🏻👍🏻👍🏻\n",
      "5 - Áo đẹp,chất lượng\n",
      "Giao hàng nhanh\n",
      "Đóng hàng kĩ\n",
      "(Đừng để ý đến ảnh và video chỉ mang tính chất nhận xu😓)\n",
      "5 - Mình mua tặng mẹ sinh nhật nên ib shop trả lời rất nhiệt tình, shop còn tặng mẹ mình thiệp sinh nhật cơ, đồ khá được, mẹ mình thích dáng của quần lắm <3\n",
      "5 - Hàng đẹp y hình, rất đáng mua nhé!\n",
      "5 - Chất vải đẹp, mua làm quà tặng rất hợp lý, mẹ mình khen tấm tắc. còn dặn mình đặt hộ tặng mấy cô bạn nữa. Yêu lắm.\n",
      "5 - Shop tư vấn nhiệt tình hỗ trợ mình đổi sz 🥰 siêu ưng luôn ý chắc chắn sẽ quay lại ủng hộ shop\n",
      "5 - Chất lượng sp tuyệt vời nha \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(\"Vậy ta có tổng cộng {} comment được crawl về từ {} sản phẩm trên.\".format(len(product_reviews), len(product_urls)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vậy ta có tổng cộng 329 comment được crawl về từ 2 sản phẩm trên.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2.1.2. Crawl comment từ hai sản phẩm với URL mà ta đã bắt được từ bước trên bằng API\n",
    "* Điều hạn chế khi crawl bằng API là ta cần biết hai thông tin là ID của shop bán hàng và ID sản phẩm, câu hỏi đặt ra là làm sao để ta có dc 2 thông tin này. Khi ta tiến hành crawl URL của các sản phẩm bằng Selenium, hãy nhìn vào một URL cụ thể như hình dưới đây (chú ý vùng khoanh đỏ), mọi product's URL đều có cái này:<br>\n",
    "  ![](./images/07.png)\n",
    "* Ta có một URL's attribute là `i.34880242.2341969918`, đây chính là identifier cho sản phẩm này, với số:\n",
    "  * `34880242`: chính là ID của shop bán hàng\n",
    "  * `2341969918`: chính là ID của sản phẩm\n",
    "* Vậy ta đã có đủ thông tin để crawl data bằng API, hãy xem hàm `Crawler.getProductReviewsAPI()` bên dưới để hiểu cách nó hoạt động.\n",
    "* Vậy tóm lại quá trình crawl data bằng API\n",
    "  * Ta cần product URL mà ta crawl được bằng Selenium, đây là bắt buộc để có dc shop id và product ID\n",
    "  * Khi ta có shop ID và Product ID, chỉ cần bỏ 2 attribute này vào request của API va nhận review về"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "product_reviews = []\n",
    "\n",
    "for idx, product_url in enumerate(product_urls): # duyệt qua các product's url\n",
    "    new_reviews = Crawler.getProductReviewsAPI(product_url) # lấy tất cả reviews của product này thông qua API\n",
    "    Crawler.writeToCsv(f\"./tmp/product_reviews_00/product_{idx}.csv\", new_reviews) # ghi mọi review của sản phẩm này ra file\n",
    "    \n",
    "    product_reviews += new_reviews # thêm vào để kiểm tra (thực tế ko sài cái này, ignore nó)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Nhận xét**\n",
    "> * Việc ta crawl bằng API tiết kiệm thời gian crawl đáng kể hơn là bằng Selenium."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "for review in product_reviews[:10]:\n",
    "    print(f\"{review.irating} - {review.icomment}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5 - Áo siêu mát luônnn í,chất đẹp lắm mua cho bà mà ưnggg hết sứcccc!!!!!!!Nên mua nhé mọi người rất hợp với ng già hoặc mua cho mẹ cũng hợp luôn😍\n",
      "5 - Đồ đẹp sang vải mát mịn nhé mẹ mình khen đẹp nhìn trẻ hẳn ra giao hàng cũng nhanh\n",
      "5 - Shop giao hàng rất nhanh và tư vấn rất nhiệt tình. Nhận đc hàng mình thấy khá ưng ý.\n",
      "Clip chỉ mang tính nhận xu ạ\n",
      "5 - Chất mát, nhẹ, mềm mịn mặc lên cảm giác siêu nhẹ mà mát lắm lắm luôn 👍🏻👍🏻👍🏻\n",
      "5 - Áo đẹp,chất lượng\n",
      "Giao hàng nhanh\n",
      "Đóng hàng kĩ\n",
      "(Đừng để ý đến ảnh và video chỉ mang tính chất nhận xu😓)\n",
      "5 - Mình mua tặng mẹ sinh nhật nên ib shop trả lời rất nhiệt tình, shop còn tặng mẹ mình thiệp sinh nhật cơ, đồ khá được, mẹ mình thích dáng của quần lắm <3\n",
      "5 - Hàng đẹp y hình, rất đáng mua nhé!\n",
      "5 - Chất vải đẹp, mua làm quà tặng rất hợp lý, mẹ mình khen tấm tắc. còn dặn mình đặt hộ tặng mấy cô bạn nữa. Yêu lắm.\n",
      "5 - Shop tư vấn nhiệt tình hỗ trợ mình đổi sz 🥰 siêu ưng luôn ý chắc chắn sẽ quay lại ủng hộ shop\n",
      "5 - Chất lượng sp tuyệt vời nha \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(\"Vậy ta có tổng cộng {} comment được crawl về từ {} sản phẩm trên.\".format(len(product_reviews), len(product_urls)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vậy ta có tổng cộng 305 comment được crawl về từ 2 sản phẩm trên.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}