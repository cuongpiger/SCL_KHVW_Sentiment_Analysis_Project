{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import modules.eda as Detective\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "reviews = pd.read_csv(\"./data/normalize_reviews.csv\").fillna(\"\")\n",
    "reviews = reviews[['raw_comment', 'normalize_comment', 'emoji', 'label']]\n",
    "\n",
    "reviews.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>emoji</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giao hàng kh đúng cần phê bình hjjjjjhhd...</td>\n",
       "      <td>giao hàng không đúng cần phê bình</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chất lượng sản phẩm tạm được. Giao...</td>\n",
       "      <td>chất lượng sản phẩm tạm được giao ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ko có lắc tay như hình</td>\n",
       "      <td>không có lắc tay như hình</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Giao hàng lâu. Bảo có lắc tay mà k thâ...</td>\n",
       "      <td>giao hàng lâu bảo có lắc tay mà không ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mình mua 2 cái, một dùng ok. Một cái k...</td>\n",
       "      <td>mua cái một dùng ok một cái không chạ...</td>\n",
       "      <td>😢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_comment  \\\n",
       "0  Giao hàng kh đúng cần phê bình hjjjjjhhd...   \n",
       "1  Chất lượng sản phẩm tạm được. Giao...   \n",
       "2                        Ko có lắc tay như hình   \n",
       "3  Giao hàng lâu. Bảo có lắc tay mà k thâ...   \n",
       "4  Mình mua 2 cái, một dùng ok. Một cái k...   \n",
       "\n",
       "                                   normalize_comment emoji  label  \n",
       "0           giao hàng không đúng cần phê bình            0  \n",
       "1  chất lượng sản phẩm tạm được giao ...            0  \n",
       "2                    không có lắc tay như hình            0  \n",
       "3  giao hàng lâu bảo có lắc tay mà không ...            0  \n",
       "4  mua cái một dùng ok một cái không chạ...     😢      0  "
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hiện tại, dataset chúng ta có hai feature là `normalize_comment` và `emoji`, chúng ta có thể xây dựng một sentiment analysis classifier bằng hai cách:\n",
    "  * **Cách 1**: Chúng ta có thể đem feature `emoji` để thêm vào phần đầu hoặc cuối của feature `normalize_comment`. Sau đó tiến hành đào tạo một model duy nhất với input là feature `normalize_comment` đã được thêm vào feature `emoji`.\n",
    "    * Ưu điểm: Quá trình đào tạo model đỡ tốn thời gian hơn do ta chỉ thực hiện build một model duy nhất.\n",
    "    * Nhược điểm:\n",
    "      * Có khả năng làm suy giảm sức mạnh của model, nhiều người họ còn xây dưng riêng một **emoji classifier** bởi vì theo họ nhiều khi emoji đó mang lại ý nghĩa thậm chí còn cao hơn so với ngữ nghĩa của comment đó. Trong khi việc đào tạo một emoji classifier đỡ vất vã hơn.\n",
    "      * Ta phải tốn thời gian vào việc xây dựng thêm một model riêng sau đó lại tổng hợp kết quả của emoji classifier model này với sentiment classifier model ban đầu.\n",
    "  * **Cách 2**: Ta có thể xây dựng hai model riêng biệt, một sentiment analysis model đảm nhận nhiệm vụ phân lớp cho câu chữ và một emoji analysis model đảm nhận nhiệm vụ phân lớp trên emoji. Sau đó ta kết hợp hai model này để cho ra kết quả phân lớp cuối cùng.\n",
    "    * Ưu điểm: Kết quả phân lớp cho ra có khả năng chính xác hơn, ta có thể linh hoạt trong việc thiếp lập trọng số để ưu tiên giá trị của model nào mang lại lợi ích cao hơn cho kết quả ở bước kết hợp hai model lại để dự đoán.\n",
    "    * Nhược điểm:\n",
    "      * Vất vả hơn về mặt tiền xử lí dữ liệu, tốn thêm thời gian phân tích và thiết kế thêm một emoji classifier.\n",
    "      * Phần lớn trong dataset hiện tại, số comment chứa emoji không nhiều. Như project 2 ta đã thấy toàn bộ dataset của ta chỉ khoảng 1300 comment là có chứa emoji kèm theo, ta có thể khắc phục bằng một trong những cách:\n",
    "        * Crawl thêm data, nhưng việc này không khả khi. Ta đã đề cập rằng số comment chứa emoji rất ít trong một dataset nên việc ta hi sinh thời gian chỉ để trích xuất một phần nhỏ trong một dataset cực lớn sau khi crawl về có thể phí phạm.\n",
    "        * Sử dụng kĩ thuật **Data Upsampler** với package của IBM `from imblearn.over_sampling import RandomOverSampler`.\n",
    "\n",
    "    $\\Rightarrow$ Hướng giải quyết: Quả thật ta có khoảng 1300 observer thì là một con số không quá ít cũng không quá nhiều, số lượng emoji chứa trong một comment cũng không nhiều (không tính các duplicate emoji). Bài toán của chúng ta đơn thuần chỉ là phân tích các emoji ra hai class là negative và positive. Hãy cùng nhìn lại một dataset nổi tiếng khác là **Iris**, ta có 3 class ở target variable và 150 observe. Vậy ta vẫn có thể build một classifier model đủ tốt nếu input của ta cũng **đủ tốt**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Emoji sentiment analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Như vậy chiến lược đào tạo một Emoji sentiment analysis của chúng ta sẽ như sau:\n",
    "  * Bước 1: Tiến hành lấy toàn bộ các emoji trong các comment và lưu trong cấu trúc dữ liệu `set`, mục tiêu ta cần biết có bao nhiêu unique emoji trong dataset của chúng ta.\n",
    "  * Bước 2: Tạo 2 dictionary, một dictionary có key là emoji và value là index của emoji đó trong `set`, dictionary thứ hai có key là index của emoji trong `set` và value là emoji.\n",
    "  * Bước 3: Giả sử có $n$ unique emoji trong dataset, ta sẽ chỉ quan tâm đến các comment chứa emoji, và với từng comment như vậy ta tạo một vector $n$ phần tử sau đó áp dụng phương pháp **Bag of words** lên vector này.\n",
    "  * Bước 4: Xem xét $n$ có lớn không, nếu quá lớn thì có thể áp dụng các phương pháp giảm chiều dữ liệu.\n",
    "  * Bước 5: Dùng các vector $n$ phần tử + label của chúng sau khi đã qua bước 4 để đào tạo một classifier model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}