{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!python3 --version\n",
    "!pip3 list"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Python 3.8.10\n",
      "Package                 Version\n",
      "----------------------- --------------------\n",
      "absl-py                 0.13.0\n",
      "anyio                   3.2.1\n",
      "appdirs                 1.4.3\n",
      "apturl                  0.5.2\n",
      "argon2-cffi             20.1.0\n",
      "astunparse              1.6.3\n",
      "async-generator         1.10\n",
      "attrs                   21.2.0\n",
      "autopep8                1.5.7\n",
      "Babel                   2.9.1\n",
      "backcall                0.2.0\n",
      "beautifulsoup4          4.9.3\n",
      "bitarray                2.3.3\n",
      "bleach                  3.3.0\n",
      "blinker                 1.4\n",
      "Brlapi                  0.7.0\n",
      "cachetools              4.2.2\n",
      "certifi                 2019.11.28\n",
      "cffi                    1.14.5\n",
      "chardet                 3.0.4\n",
      "chrome-gnome-shell      0.0.0\n",
      "clang                   5.0\n",
      "Click                   7.0\n",
      "colorama                0.4.3\n",
      "command-not-found       0.3\n",
      "cryptography            2.8\n",
      "cupshelpers             1.0\n",
      "cycler                  0.10.0\n",
      "dbus-python             1.2.16\n",
      "decorator               5.0.9\n",
      "defer                   1.0.6\n",
      "defusedxml              0.7.1\n",
      "distlib                 0.3.0\n",
      "distro                  1.4.0\n",
      "distro-info             0.23ubuntu1\n",
      "docutils                0.16\n",
      "emoji                   1.2.0\n",
      "emojis                  0.6.0\n",
      "entrypoints             0.3\n",
      "et-xmlfile              1.1.0\n",
      "evdev                   1.4.0\n",
      "fasttext                0.9.2\n",
      "filelock                3.0.12\n",
      "flatbuffers             1.12\n",
      "future                  0.18.2\n",
      "gast                    0.4.0\n",
      "google-auth             1.35.0\n",
      "google-auth-oauthlib    0.4.5\n",
      "google-pasta            0.2.0\n",
      "gpg                     1.13.1-unknown\n",
      "graphviz                0.17\n",
      "grpcio                  1.39.0\n",
      "h5py                    3.1.0\n",
      "html5lib                1.1\n",
      "httplib2                0.14.0\n",
      "idna                    2.8\n",
      "imbalanced-learn        0.8.0\n",
      "importlib-metadata      1.5.0\n",
      "ipykernel               5.5.5\n",
      "ipython                 7.23.1\n",
      "ipython-genutils        0.2.0\n",
      "ipywidgets              7.6.3\n",
      "jedi                    0.18.0\n",
      "Jinja2                  3.0.1\n",
      "JLDracula               0.1.0\n",
      "joblib                  1.0.1\n",
      "json5                   0.9.6\n",
      "jsonschema              3.2.0\n",
      "jupyter                 1.0.0\n",
      "jupyter-client          6.1.12\n",
      "jupyter-console         6.4.0\n",
      "jupyter-core            4.7.1\n",
      "jupyter-server          1.9.0\n",
      "jupyterlab              3.0.16\n",
      "jupyterlab-pygments     0.1.2\n",
      "jupyterlab-server       2.6.0\n",
      "jupyterlab-widgets      1.0.0\n",
      "keras                   2.6.0\n",
      "Keras-Preprocessing     1.1.2\n",
      "keyring                 18.0.1\n",
      "kiwisolver              1.3.1\n",
      "language-selector       0.1\n",
      "launchpadlib            1.10.13\n",
      "lazr.restfulclient      0.14.2\n",
      "lazr.uri                1.0.3\n",
      "linecache2              1.0.0\n",
      "louis                   3.12.0\n",
      "lxml                    4.6.3\n",
      "macaroonbakery          1.3.1\n",
      "Markdown                3.3.4\n",
      "Markups                 3.0.0\n",
      "MarkupSafe              2.0.1\n",
      "matplotlib              3.4.2\n",
      "matplotlib-inline       0.1.2\n",
      "mistune                 0.8.4\n",
      "more-itertools          4.2.0\n",
      "nbclassic               0.3.1\n",
      "nbclient                0.5.3\n",
      "nbconvert               6.0.7\n",
      "nbformat                5.1.3\n",
      "nest-asyncio            1.5.1\n",
      "netifaces               0.10.4\n",
      "nltk                    3.6.2\n",
      "notebook                6.4.0\n",
      "numpy                   1.19.5\n",
      "oauthlib                3.1.0\n",
      "olefile                 0.46\n",
      "openpyxl                3.0.9\n",
      "opt-einsum              3.3.0\n",
      "packaging               20.9\n",
      "pandas                  1.2.4\n",
      "pandocfilters           1.4.3\n",
      "parso                   0.8.2\n",
      "patsy                   0.5.2\n",
      "pbr                     5.4.5\n",
      "pexpect                 4.6.0\n",
      "pickleshare             0.7.5\n",
      "Pillow                  7.0.0\n",
      "pimg                    0.0.1\n",
      "pip                     21.3.1\n",
      "plotly                  5.3.1\n",
      "prometheus-client       0.11.0\n",
      "prompt-toolkit          3.0.18\n",
      "protobuf                3.17.3\n",
      "ptyprocess              0.7.0\n",
      "py4j                    0.10.9\n",
      "pyasn1                  0.4.8\n",
      "pyasn1-modules          0.2.8\n",
      "pybind11                2.8.1\n",
      "pycairo                 1.16.2\n",
      "pyclean                 2.0.0\n",
      "pycodestyle             2.7.0\n",
      "pycparser               2.20\n",
      "pycups                  1.9.73\n",
      "pydot                   1.4.2\n",
      "pydotplus               2.0.2\n",
      "pyenchant               3.2.1\n",
      "Pygments                2.9.0\n",
      "PyGObject               3.36.0\n",
      "PyJWT                   1.7.1\n",
      "pymacaroons             0.13.0\n",
      "PyNaCl                  1.3.0\n",
      "pynput                  1.7.3\n",
      "pyodbc                  4.0.30\n",
      "pyparsing               2.4.7\n",
      "pyperclip               1.8.2\n",
      "PyQt5                   5.14.1\n",
      "pyRFC3339               1.1\n",
      "pyrsistent              0.17.3\n",
      "PySide2                 5.15.2\n",
      "PySocks                 1.6.8\n",
      "pyspark                 3.1.2\n",
      "python-apt              2.0.0+ubuntu0.20.4.6\n",
      "python-crfsuite         0.9.7\n",
      "python-dateutil         2.7.3\n",
      "python-debian           0.1.36ubuntu1\n",
      "python-markdown-math    0.6\n",
      "python-xlib             0.30\n",
      "pytz                    2019.3\n",
      "pyvi                    0.1\n",
      "pyxdg                   0.26\n",
      "PyYAML                  5.3.1\n",
      "pyzmq                   22.0.3\n",
      "qtconsole               5.1.0\n",
      "QtPy                    1.9.0\n",
      "regex                   2021.4.4\n",
      "reportlab               3.5.34\n",
      "requests                2.22.0\n",
      "requests-oauthlib       1.3.0\n",
      "requests-unixsocket     0.2.0\n",
      "roman                   2.0.0\n",
      "rsa                     4.7.2\n",
      "sacremoses              0.0.45\n",
      "scikit-learn            0.24.2\n",
      "scipy                   1.6.3\n",
      "screen-resolution-extra 0.0.0\n",
      "seaborn                 0.11.2\n",
      "SecretStorage           2.3.1\n",
      "selenium                3.141.0\n",
      "Send2Trash              1.5.0\n",
      "sentencepiece           0.1.91\n",
      "seqeval                 1.2.2\n",
      "setuptools              45.2.0\n",
      "shiboken2               5.15.2\n",
      "simplejson              3.16.0\n",
      "sip                     4.19.21\n",
      "six                     1.15.0\n",
      "sklearn-crfsuite        0.3.6\n",
      "sniffio                 1.2.0\n",
      "soupsieve               2.2.1\n",
      "statsmodels             0.13.0\n",
      "stevedore               3.4.0\n",
      "systemd-python          234\n",
      "tabulate                0.8.9\n",
      "tenacity                8.0.1\n",
      "tensorboard             2.7.0\n",
      "tensorboard-data-server 0.6.1\n",
      "tensorboard-plugin-wit  1.8.0\n",
      "tensorflow-estimator    2.6.0\n",
      "tensorflow-gpu          2.6.0\n",
      "termcolor               1.1.0\n",
      "terminado               0.10.0\n",
      "testpath                0.5.0\n",
      "testresources           2.0.0\n",
      "textblob                0.15.3\n",
      "textile                 4.0.1\n",
      "threadpoolctl           2.1.0\n",
      "tokenizers              0.9.3\n",
      "toml                    0.10.2\n",
      "torbrowser-launcher     0.3.2\n",
      "torch                   1.9.0\n",
      "torchaudio              0.9.0\n",
      "torchvision             0.10.0\n",
      "tornado                 6.1\n",
      "tqdm                    4.61.0\n",
      "traceback2              1.4.0\n",
      "traitlets               5.0.5\n",
      "transformers            3.5.1\n",
      "typing-extensions       3.7.4.3\n",
      "ubuntu-advantage-tools  27.2\n",
      "ubuntu-drivers-common   0.0.0\n",
      "ufw                     0.36\n",
      "unattended-upgrades     0.1\n",
      "underthesea             1.3.1\n",
      "Unidecode               1.2.0\n",
      "unittest2               1.1.0\n",
      "urllib3                 1.25.8\n",
      "usb-creator             0.3.7\n",
      "vboxapi                 1.0\n",
      "virtualenv              20.0.17\n",
      "virtualenv-clone        0.5.6\n",
      "virtualenvwrapper       4.8.4\n",
      "vncorenlp               1.0.3\n",
      "wadllib                 1.3.3\n",
      "wcwidth                 0.2.5\n",
      "webencodings            0.5.1\n",
      "websocket-client        1.1.0\n",
      "Werkzeug                2.0.1\n",
      "wheel                   0.37.0\n",
      "widgetsnbextension      3.5.1\n",
      "wordcloud               1.8.1\n",
      "wrapt                   1.12.1\n",
      "xgboost                 1.4.2\n",
      "xkit                    0.0.0\n",
      "xlrd                    2.0.1\n",
      "XlsxWriter              3.0.1\n",
      "zipp                    1.0.0\n",
      "zmq                     0.0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tóm tắt quá trình\n",
    "Ở project 3 bài chúng ta sẽ lần lượt làm các công việc sau:\n",
    "* **Công việc 1**: Chia bô dữ liệu thành hai phần training data và test data nhằm đảm bảo tính công bằng trên mọi model.\n",
    "* **Công việc 2**: Chia bài toán ban đầu thành hai bài toán con là **Emoji sentiment model** và **Comment sentiment model** và giải thích lí do.\n",
    "  * **Cộng việc 2.1**: Xây dựng **Emoji sentiment model**. \n",
    "    * Xác định input và cách biểu diễn nó sau đó lựa chọn cách biểu diễn phù hợp.\n",
    "    * Xác định output.\n",
    "    * Tiến hành sử dụng các **Traditional Machine Learning Classifier** để đào tạo.\n",
    "    * Tối ưu hóa tham số bằng phương pháp **Grid Search**.\n",
    "    * Đánh giá model.\n",
    "    * Lưu lại model.\n",
    "  * **Công việc 2.2**: Xây dựng **Comment sentiment model**.\n",
    "    * Xác định input và cách biểu diễn nó sau đó lựa chọn cách biểu diễn phù hợp.\n",
    "    * Xác định output.\n",
    "    * Tiến hành sử dụng các **Traditional Machine Learning Classifier** để đào tạo.\n",
    "    * Tiến hành sử dũng các **Deep Learning** để đào tạo.\n",
    "    * Tối ưu hóa tham số bằng phương pháp **HyperBand**.\n",
    "    * Đánh giá model.\n",
    "    * Lưu lại model.\n",
    "* **Công việc 3**: Tổng hợp hai model **Emoji sentiment** và **Comment sentiment** để ra model cuối cùng."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import modules.model as Model\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Công việc 1:\n",
    "* Phần này ta sẽ tách dữ liệu sau khi trải qua các bước tiền xử lí ở project 1 thành training data và test data. \n",
    "* Lí do ta cần thực hiện điều này là ta muốn đảm bảo công bằng cho mọi model trong quá trình đào tạo, tức chúng cùng học trên cùng một training data và được đánh giá trên cùng một test data.\n",
    "* Như ở **công việc 2** đã trình bày, ta sẽ chia dữ liệu sau tiền xử lí thành hai phần:\n",
    "  * **Phần dữ liệu chỉ chứa emoji**: phần dữ liệu này chỉ chứa các comment chứa emoji, các comment không chứa emoji ta sẽ loại bỏ.\n",
    "  * **Phần dữ liệu chỉ chứa comment**: phần dữ liệu này chính là phần dữ liệu ban đầu nhưng khác một điều toàn bộ emoji trong comment sẽ bị xóa. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Đọc toàn bộ dữ liệu sau khi đã tiền xử lí ở project 1."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data = pd.read_csv(\"./data/normalize_reviews.csv\").fillna(\"\")[['raw_comment', 'normalize_comment', 'label']]\n",
    "\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giao hàng kh đúng cần phê bình hjjjjjhhd...</td>\n",
       "      <td>giao hàng không đúng cần phê bình</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chất lượng sản phẩm tạm được. Giao...</td>\n",
       "      <td>chất lượng sản phẩm tạm được giao ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ko có lắc tay như hình</td>\n",
       "      <td>không có lắc tay như hình</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Giao hàng lâu. Bảo có lắc tay mà k thâ...</td>\n",
       "      <td>giao hàng lâu bảo có lắc tay mà không ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mình mua 2 cái, một dùng ok. Một cái k...</td>\n",
       "      <td>mua cái một dùng ok một cái không chạ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_comment  \\\n",
       "0  Giao hàng kh đúng cần phê bình hjjjjjhhd...   \n",
       "1  Chất lượng sản phẩm tạm được. Giao...   \n",
       "2                        Ko có lắc tay như hình   \n",
       "3  Giao hàng lâu. Bảo có lắc tay mà k thâ...   \n",
       "4  Mình mua 2 cái, một dùng ok. Một cái k...   \n",
       "\n",
       "                                   normalize_comment  label  \n",
       "0           giao hàng không đúng cần phê bình      0  \n",
       "1  chất lượng sản phẩm tạm được giao ...      0  \n",
       "2                    không có lắc tay như hình      0  \n",
       "3  giao hàng lâu bảo có lắc tay mà không ...      0  \n",
       "4  mua cái một dùng ok một cái không chạ...      0  "
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mã hóa các dữ liệu dạng text về cùng một dạng là **NFD**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data = Model.textNFxformat(data, ['raw_comment', 'normalize_comment'], 'NFD')\n",
    "\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giao hàng kh đúng cần phê bình hjjjjjhhd...</td>\n",
       "      <td>giao hàng không đúng cần phê bình</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chất lượng sản phẩm tạm được. Giao...</td>\n",
       "      <td>chất lượng sản phẩm tạm được giao ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ko có lắc tay như hình</td>\n",
       "      <td>không có lắc tay như hình</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Giao hàng lâu. Bảo có lắc tay mà k thâ...</td>\n",
       "      <td>giao hàng lâu bảo có lắc tay mà không ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mình mua 2 cái, một dùng ok. Một cái k...</td>\n",
       "      <td>mua cái một dùng ok một cái không chạ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_comment  \\\n",
       "0  Giao hàng kh đúng cần phê bình hjjjjjhhd...   \n",
       "1  Chất lượng sản phẩm tạm được. Giao...   \n",
       "2                        Ko có lắc tay như hình   \n",
       "3  Giao hàng lâu. Bảo có lắc tay mà k thâ...   \n",
       "4  Mình mua 2 cái, một dùng ok. Một cái k...   \n",
       "\n",
       "                                   normalize_comment  label  \n",
       "0           giao hàng không đúng cần phê bình      0  \n",
       "1  chất lượng sản phẩm tạm được giao ...      0  \n",
       "2                    không có lắc tay như hình      0  \n",
       "3  giao hàng lâu bảo có lắc tay mà không ...      0  \n",
       "4  mua cái một dùng ok một cái không chạ...      0  "
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Các vectorizer object của **sklearn** mặc định chúng sẽ xóa toàn bộ các **punctuation** [kí tự đặc biệt] trong input truyền vào. Như vậy các emoji của ta sẽ bị xóa toàn bộ khi transform vectorizing. Như vậy, ta sẽ không lưu chúng dưới dạng các punctuation mà dùng decode của chúng - ta sẽ tạo một feature `emoji_decode` để lưu chúng.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "data['emoji_decode'] = data['raw_comment'].apply(lambda s: Model.expandEmojisDecode(s))\n",
    "data = data[['raw_comment', 'normalize_comment', 'emoji_decode', 'label']]\n",
    "\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>emoji_decode</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giao hàng kh đúng cần phê bình hjjjjjhhd...</td>\n",
       "      <td>giao hàng không đúng cần phê bình</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chất lượng sản phẩm tạm được. Giao...</td>\n",
       "      <td>chất lượng sản phẩm tạm được giao ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ko có lắc tay như hình</td>\n",
       "      <td>không có lắc tay như hình</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Giao hàng lâu. Bảo có lắc tay mà k thâ...</td>\n",
       "      <td>giao hàng lâu bảo có lắc tay mà không ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mình mua 2 cái, một dùng ok. Một cái k...</td>\n",
       "      <td>mua cái một dùng ok một cái không chạ...</td>\n",
       "      <td>cry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_comment  \\\n",
       "0  Giao hàng kh đúng cần phê bình hjjjjjhhd...   \n",
       "1  Chất lượng sản phẩm tạm được. Giao...   \n",
       "2                        Ko có lắc tay như hình   \n",
       "3  Giao hàng lâu. Bảo có lắc tay mà k thâ...   \n",
       "4  Mình mua 2 cái, một dùng ok. Một cái k...   \n",
       "\n",
       "                                   normalize_comment emoji_decode  label  \n",
       "0           giao hàng không đúng cần phê bình                   0  \n",
       "1  chất lượng sản phẩm tạm được giao ...                   0  \n",
       "2                    không có lắc tay như hình                   0  \n",
       "3  giao hàng lâu bảo có lắc tay mà không ...                   0  \n",
       "4  mua cái một dùng ok một cái không chạ...          cry      0  "
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tiến hành chọn các mẫu có feature `emoji_decode` không phải là chuổi rỗng và lưu vào biến `emoji_data`. Các mẫu trong biến này sẽ được dùng để xây dựng một **Emoji sentiment model**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "emoji_data = data[data['emoji_decode'] != \"\"].reset_index(drop=True)\n",
    "\n",
    "emoji_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>emoji_decode</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mình mua 2 cái, một dùng ok. Một cái k...</td>\n",
       "      <td>mua cái một dùng ok một cái không chạ...</td>\n",
       "      <td>cry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Giao sai màu sai size có 1 dép lông size 3...</td>\n",
       "      <td>giao sai màu sai size có dép lông size à ...</td>\n",
       "      <td>cursing_face cursing_face cursing_face</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Đơn hàng đã thanh toán airpay rồi mà sh...</td>\n",
       "      <td>đơn hàng thanh toán mà giao cho người l...</td>\n",
       "      <td>roll_eyes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Áo croptop freesize rộng với mình \\nMìn...</td>\n",
       "      <td>áo rộng mình kg</td>\n",
       "      <td>thumbsup thumbsup thumbsup thumbsup thumbsup t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Khá buồn . Đặt 2 cái đều không chạy ...</td>\n",
       "      <td>khá buồn đặt cái đều không chạy giơ...</td>\n",
       "      <td>female_sign shrug</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_comment  \\\n",
       "0  Mình mua 2 cái, một dùng ok. Một cái k...   \n",
       "1  Giao sai màu sai size có 1 dép lông size 3...   \n",
       "2  Đơn hàng đã thanh toán airpay rồi mà sh...   \n",
       "3  Áo croptop freesize rộng với mình \\nMìn...   \n",
       "4  Khá buồn . Đặt 2 cái đều không chạy ...   \n",
       "\n",
       "                                   normalize_comment  \\\n",
       "0  mua cái một dùng ok một cái không chạ...   \n",
       "1  giao sai màu sai size có dép lông size à ...   \n",
       "2  đơn hàng thanh toán mà giao cho người l...   \n",
       "3                                áo rộng mình kg   \n",
       "4  khá buồn đặt cái đều không chạy giơ...   \n",
       "\n",
       "                                        emoji_decode  label  \n",
       "0                                                cry      0  \n",
       "1             cursing_face cursing_face cursing_face      0  \n",
       "2                                          roll_eyes      0  \n",
       "3  thumbsup thumbsup thumbsup thumbsup thumbsup t...      0  \n",
       "4                                  female_sign shrug      0  "
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Giờ thì ta sẽ tiến hành chia `emoji_data` thành training data và test data với size của test data là 20%, sau đó ta lưu chúng dưới dạng file **.csv**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "Model.dataSplitSaved(emoji_data, 0.2, \"./data/emoji_data\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "📢 Your dataset has saved at ./data/emoji_data.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bây giờ ta cần chuẩn bị training data và test data cho **Comment sentiment model**, ta cũng sẽ chia tập dữ liệu sau tiền xử lí thành hai phần training data và test data với test data chiếm 20% dữ liệu sau tiền xử lí. Cuối cùng ta cũng sẽ lưu hai tập training data và test data này dưới dạng file **.csv**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>emoji_decode</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giao hàng kh đúng cần phê bình hjjjjjhhd...</td>\n",
       "      <td>giao hàng không đúng cần phê bình</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chất lượng sản phẩm tạm được. Giao...</td>\n",
       "      <td>chất lượng sản phẩm tạm được giao ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ko có lắc tay như hình</td>\n",
       "      <td>không có lắc tay như hình</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Giao hàng lâu. Bảo có lắc tay mà k thâ...</td>\n",
       "      <td>giao hàng lâu bảo có lắc tay mà không ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mình mua 2 cái, một dùng ok. Một cái k...</td>\n",
       "      <td>mua cái một dùng ok một cái không chạ...</td>\n",
       "      <td>cry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_comment  \\\n",
       "0  Giao hàng kh đúng cần phê bình hjjjjjhhd...   \n",
       "1  Chất lượng sản phẩm tạm được. Giao...   \n",
       "2                        Ko có lắc tay như hình   \n",
       "3  Giao hàng lâu. Bảo có lắc tay mà k thâ...   \n",
       "4  Mình mua 2 cái, một dùng ok. Một cái k...   \n",
       "\n",
       "                                   normalize_comment emoji_decode  label  \n",
       "0           giao hàng không đúng cần phê bình                   0  \n",
       "1  chất lượng sản phẩm tạm được giao ...                   0  \n",
       "2                    không có lắc tay như hình                   0  \n",
       "3  giao hàng lâu bảo có lắc tay mà không ...                   0  \n",
       "4  mua cái một dùng ok một cái không chạ...          cry      0  "
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "Model.dataSplitSaved(data, 0.2, \"./data/data\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "📢 Your dataset has saved at ./data/data.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Công việc 2:\n",
    "* Ở phần này, nhóm sẽ trình bày về các vấn đề sau:\n",
    "  * **Vấn đề 1**: Lựa chọn thuật toán tương ứng lần lượt cho hai model và lí giải.\n",
    "  * **Vấn đề 2**: Lựa chọn kĩ thuật đánh giá. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vấn đề 1:\n",
    "* Bài toán của chúng ta là NLP - như vậy thì dữ liệu sẽ khiến cho chúng ta khó hiểu hơn về dữ liệu. Nhưng theo những gì nhóm đã được học ở những môn trước thì nhóm có hi vọng cao vào hai thuật toán là **Logistic Regression** và **Support Vector Machine**. Tuy nhiên nhóm vẫn sẽ áp dụng các model classification khác như Naive Bayes, Random Forest,... vì khả năng cao chúng có thể đại diện tốt cho dataset của chúng ta.\n",
    "\n",
    "#### Logistic Regession:\n",
    "* Ở phần đào tạo mô hình sau này, nhóm sẽ ưu tiên sử dụng thuật toán này trên các `solver` khác nhau như `newton-cg`, `lbfgs`, `liblinear`. Đây là một sự ưu tiên cho thuật toán này vì nhóm nghĩ nó hiệu quả vì:\n",
    "  * Bài toán của chúng ta là **binary classification** và **Logistic Regression** thường được coi là thuật toán cơ bản nhất cho các bài toán dạng này.\n",
    "  * Thuật toán **Logistic Regression** có thời gian thực thi nhanh và cách cài đặt đơn giản, các **hyper-parameter** không nhiều nên dễ dàng thực hiện kĩ thuật **Tunning Hyper-Parameters**.\n",
    "  * Đối với **Emoji sentiment model**, thực chất số lượng emoji mà người dùng hay dùng không nhiều, số emoji trong một comment cũng không nhiều $\\Rightarrow$ Khiến cho dữ liệu đào tạo đơn giản và dễ hiệu nên **Logistic Regression** rất phù hợp với các dataset đơn giản như vậy đồng thời sẽ cho ra độ chính xác cao.\n",
    "  * Với **Comment sentiment model** - dữ liệu phức tạp hơn nhưng chúng ta cũng nên kì vọng là thuật toán này sẽ hoạt động tốt.\n",
    "  \n",
    "#### Support Vector Machine\n",
    "* Do nhóm nghĩ đây là một thuật toán hiệu quả, nên nhóm cũng sẽ có chút ưu tiên cho thuật toán bày bằng cách triển khai nó trên nhiều `kernel` khác nhau như `linear`, `poly`, `rbf`, `sigmoid`. Lí do nhóm ưu tiên thuật toán này là vì:\n",
    "  * Với các dữ liệu mà ta khó có cái nhìn tổng quan hoặc ý tưởng thì SVM là một mô hình khá tốt để ta tiến hành đào tạo vì nó linh hoạt - có thể dùng cho hai bài toán là **regression** và **classification** thậm chí là cho cả các bài toán **clustering**.\n",
    "  * Nó hoạt động tốt trên dữ liệu phức tạp mà với dữ liệu text thì text hay được biểu diễn dưới dạng vector.\n",
    "  * Với các bài toán phân lớp, nó sử dụng các `kernel` để đưa input đầu vào vào một không gian có nhiều chiều hơn ngoài ra còn cố gắng tối đa hóa khoảng cách giữa **sepertating hyperplan** với các **super vectors**.<br>\n",
    "    ![](./images/10.png)\n",
    "  * Hoạt động hiệu quả trên bài toán phân loại văn bản, dữ liệu phi cấu trúc và nhiều chiều.\n",
    "  * Ngoài ra, sức mạnh của thuật toán này chính là dựa trên các `kernel` mà ta lựa chọn, tuy nhiên để chọn ra `kernel` tốt không dễ dàng nên ta thường vét cạn, nhưng nếu dữ liệu quá lớn thì không nên vì thời gian đào tạo của thuật toán này lâu, có thể nói ngang ngữa với các **Deep Neural Network**.\n",
    "\n",
    "#### Deep Neural Netword\n",
    "* Các thuật toán thuộc nhóm DNN sẽ được trình bày sau. Nhóm sẽ tập trung trình bày vào LSTM vì đây là model hoạt động tốt nhất trên dataset của nhóm."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vấn đề 2:\n",
    "![](./images/11.png)\n",
    "* Chúng ta sẽ sử dụng hai độ đo phổ biến nhất dành cho các classification model là:\n",
    "  * **Accuracy**: dùng để đánh giá độ chính xác của model trên **TN** và **TP**.\n",
    "  * **ROC-AUC**: accuracy sẽ không chính xác nếu như số lượng mẫu giữa các class bị mất cân năng nên ROC-AUC sẽ giúp ta kiểm tra việc xem có một class nào nổi trội hơn so với class còn lại không."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bây giờ ta sẽ tiến hành build một **Emoji sentiment model**"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}