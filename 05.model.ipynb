{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import modules.eda as Detective\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import emojis\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def expandEmojisDecode(pcomment: str):\n",
    "    expand_emojis = ''\n",
    "    for e in emojis.get(pcomment):\n",
    "        amount = pcomment.count(e)\n",
    "        expand_emojis += (f\"{emojis.decode(e)[1:-1]} \")*amount\n",
    "        \n",
    "    return expand_emojis.strip()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "reviews = pd.read_csv(\"./data/normalize_reviews.csv\").fillna(\"\")\n",
    "reviews = reviews[['raw_comment', 'normalize_comment', 'emoji', 'label']]\n",
    "\n",
    "reviews.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>emoji</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Giao hàng kh đúng cần phê bình hjjjjjhhd...</td>\n",
       "      <td>giao hàng không đúng cần phê bình</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chất lượng sản phẩm tạm được. Giao...</td>\n",
       "      <td>chất lượng sản phẩm tạm được giao ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ko có lắc tay như hình</td>\n",
       "      <td>không có lắc tay như hình</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Giao hàng lâu. Bảo có lắc tay mà k thâ...</td>\n",
       "      <td>giao hàng lâu bảo có lắc tay mà không ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mình mua 2 cái, một dùng ok. Một cái k...</td>\n",
       "      <td>mua cái một dùng ok một cái không chạ...</td>\n",
       "      <td>😢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_comment  ... label\n",
       "0  Giao hàng kh đúng cần phê bình hjjjjjhhd...  ...     0\n",
       "1  Chất lượng sản phẩm tạm được. Giao...  ...     0\n",
       "2                        Ko có lắc tay như hình  ...     0\n",
       "3  Giao hàng lâu. Bảo có lắc tay mà k thâ...  ...     0\n",
       "4  Mình mua 2 cái, một dùng ok. Một cái k...  ...     0\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hiện tại, dataset chúng ta có hai feature là `normalize_comment` và `emoji`, chúng ta có thể xây dựng một sentiment analysis classifier bằng hai cách:\n",
    "  * **Cách 1**: Chúng ta có thể đem feature `emoji` để thêm vào phần đầu hoặc cuối của feature `normalize_comment`. Sau đó tiến hành đào tạo một model duy nhất với input là feature `normalize_comment` đã được thêm vào feature `emoji`.\n",
    "    * Ưu điểm: Quá trình đào tạo model đỡ tốn thời gian hơn do ta chỉ thực hiện build một model duy nhất.\n",
    "    * Nhược điểm:\n",
    "      * Có khả năng làm suy giảm sức mạnh của model, nhiều người họ còn xây dưng riêng một **emoji classifier** bởi vì theo họ nhiều khi emoji đó mang lại ý nghĩa thậm chí còn cao hơn so với ngữ nghĩa của comment đó. Trong khi việc đào tạo một emoji classifier đỡ vất vã hơn.\n",
    "      * Ta phải tốn thời gian vào việc xây dựng thêm một model riêng sau đó lại tổng hợp kết quả của emoji classifier model này với sentiment classifier model ban đầu.\n",
    "  * **Cách 2**: Ta có thể xây dựng hai model riêng biệt, một sentiment analysis model đảm nhận nhiệm vụ phân lớp cho câu chữ và một emoji analysis model đảm nhận nhiệm vụ phân lớp trên emoji. Sau đó ta kết hợp hai model này để cho ra kết quả phân lớp cuối cùng.\n",
    "    * Ưu điểm: Kết quả phân lớp cho ra có khả năng chính xác hơn, ta có thể linh hoạt trong việc thiếp lập trọng số để ưu tiên giá trị của model nào mang lại lợi ích cao hơn cho kết quả ở bước kết hợp hai model lại để dự đoán.\n",
    "    * Nhược điểm:\n",
    "      * Vất vả hơn về mặt tiền xử lí dữ liệu, tốn thêm thời gian phân tích và thiết kế thêm một emoji classifier.\n",
    "      * Phần lớn trong dataset hiện tại, số comment chứa emoji không nhiều. Như project 2 ta đã thấy toàn bộ dataset của ta chỉ khoảng 1300 comment là có chứa emoji kèm theo, ta có thể khắc phục bằng một trong những cách:\n",
    "        * Crawl thêm data, nhưng việc này không khả khi. Ta đã đề cập rằng số comment chứa emoji rất ít trong một dataset nên việc ta hi sinh thời gian chỉ để trích xuất một phần nhỏ trong một dataset cực lớn sau khi crawl về có thể phí phạm.\n",
    "        * Sử dụng kĩ thuật **Data Upsampler** với package của IBM `from imblearn.over_sampling import RandomOverSampler`.\n",
    "\n",
    "    $\\Rightarrow$ Hướng giải quyết: Quả thật ta có khoảng 1300 observer thì là một con số không quá ít cũng không quá nhiều, số lượng emoji chứa trong một comment cũng không nhiều (không tính các duplicate emoji). Bài toán của chúng ta đơn thuần chỉ là phân tích các emoji ra hai class là negative và positive. Hãy cùng nhìn lại một dataset nổi tiếng khác là **Iris**, ta có 3 class ở target variable và 150 observe. Vậy ta vẫn có thể build một classifier model đủ tốt nếu input của ta cũng **đủ tốt**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Emoji sentiment analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Như vậy chiến lược đào tạo một Emoji sentiment analysis của chúng ta sẽ như sau:\n",
    "  * Bước 1: Tiến hành lấy toàn bộ các emoji trong các comment và lưu trong cấu trúc dữ liệu `set`, mục tiêu ta cần biết có bao nhiêu unique emoji trong dataset của chúng ta.\n",
    "  * Bước 2: Tạo 2 dictionary, một dictionary có key là emoji và value là index của emoji đó trong `set`, dictionary thứ hai có key là index của emoji trong `set` và value là emoji.\n",
    "  * Bước 3: Giả sử có $n$ unique emoji trong dataset, ta sẽ chỉ quan tâm đến các comment chứa emoji, và với từng comment như vậy ta tạo một vector $n$ phần tử sau đó áp dụng phương pháp **Bag of words** lên vector này.\n",
    "  * Bước 4: Xem xét $n$ có lớn không, nếu quá lớn thì có thể áp dụng các phương pháp giảm chiều dữ liệu.\n",
    "  * Bước 5: Dùng các vector $n$ phần tử + label của chúng sau khi đã qua bước 4 để đào tạo một classifier model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bây giờ ta sẽ tiến hành lọc ra nhựng comment mà có chứa emoji dựa vào feature `emoji`. Sau đó lưu các observe này vào biến `emojis`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data = reviews[reviews['emoji'] != \"\"]\n",
    "\n",
    "data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>emoji</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mình mua 2 cái, một dùng ok. Một cái k...</td>\n",
       "      <td>mua cái một dùng ok một cái không chạ...</td>\n",
       "      <td>😢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Giao sai màu sai size có 1 dép lông size 3...</td>\n",
       "      <td>giao sai màu sai size có dép lông size à ...</td>\n",
       "      <td>🤬</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Đơn hàng đã thanh toán airpay rồi mà sh...</td>\n",
       "      <td>đơn hàng thanh toán mà giao cho người l...</td>\n",
       "      <td>🙄</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Áo croptop freesize rộng với mình \\nMìn...</td>\n",
       "      <td>áo rộng mình kg</td>\n",
       "      <td>👍</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Khá buồn . Đặt 2 cái đều không chạy ...</td>\n",
       "      <td>khá buồn đặt cái đều không chạy giơ...</td>\n",
       "      <td>♀️ 🤷</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14184</th>\n",
       "      <td>Không mua hối hận đừng kêu nhá haha, ...</td>\n",
       "      <td>không mua hối hận đừng kêu nhá hàng ...</td>\n",
       "      <td>😂</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14186</th>\n",
       "      <td>khuyên xinh lắm lúc mình đặt còn đươ...</td>\n",
       "      <td>khuyên xinh lắm lúc đặt còn được dea...</td>\n",
       "      <td>😘</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14193</th>\n",
       "      <td>đẹp rẻ chất lượng vô cùng xịn 😗😗😗 ma...</td>\n",
       "      <td>đẹp rẻ chất lượng vô cùng xịn mãi u...</td>\n",
       "      <td>😗</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14194</th>\n",
       "      <td>Đẹp, sẽ ủng hộ tiếp nhé 👕👕👕👕👕👕👕👕👕👕👕👕👕👕...</td>\n",
       "      <td>đẹp sẽ ủng hộ tiếp nhé</td>\n",
       "      <td>👕</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14200</th>\n",
       "      <td>Mua về cho chồng mà để con em nó mặc...</td>\n",
       "      <td>mua về cho chồng mà con em mặc thử tr...</td>\n",
       "      <td>😂</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1283 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             raw_comment  ... label\n",
       "4      Mình mua 2 cái, một dùng ok. Một cái k...  ...     0\n",
       "15     Giao sai màu sai size có 1 dép lông size 3...  ...     0\n",
       "30     Đơn hàng đã thanh toán airpay rồi mà sh...  ...     0\n",
       "43     Áo croptop freesize rộng với mình \\nMìn...  ...     0\n",
       "47     Khá buồn . Đặt 2 cái đều không chạy ...  ...     0\n",
       "...                                                  ...  ...   ...\n",
       "14184  Không mua hối hận đừng kêu nhá haha, ...  ...     1\n",
       "14186  khuyên xinh lắm lúc mình đặt còn đươ...  ...     1\n",
       "14193  đẹp rẻ chất lượng vô cùng xịn 😗😗😗 ma...  ...     1\n",
       "14194  Đẹp, sẽ ủng hộ tiếp nhé 👕👕👕👕👕👕👕👕👕👕👕👕👕👕...  ...     1\n",
       "14200  Mua về cho chồng mà để con em nó mặc...  ...     1\n",
       "\n",
       "[1283 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Package **emojis** chỉ hỗ trợ chức năng tách emoji ra khỏi text, nó không hỗ trợ thống kê là một emoji xuất hiện bao nhiêu lần trong text đó. Bây giờ ta sẽ tách các emoji trong comment ra nhưng vẫn bảo toàn về mặt số lượng ban đầu của nó trong feature `raw_comment` và lưu vào feature `emoji`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "data['decode_emoji'] = data['raw_comment'].apply(lambda cmt: expandEmojisDecode(cmt))\n",
    "\n",
    "data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>emoji</th>\n",
       "      <th>label</th>\n",
       "      <th>decode_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mình mua 2 cái, một dùng ok. Một cái k...</td>\n",
       "      <td>mua cái một dùng ok một cái không chạ...</td>\n",
       "      <td>😢</td>\n",
       "      <td>0</td>\n",
       "      <td>cry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Giao sai màu sai size có 1 dép lông size 3...</td>\n",
       "      <td>giao sai màu sai size có dép lông size à ...</td>\n",
       "      <td>🤬</td>\n",
       "      <td>0</td>\n",
       "      <td>cursing_face cursing_face cursing_face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Đơn hàng đã thanh toán airpay rồi mà sh...</td>\n",
       "      <td>đơn hàng thanh toán mà giao cho người l...</td>\n",
       "      <td>🙄</td>\n",
       "      <td>0</td>\n",
       "      <td>roll_eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Áo croptop freesize rộng với mình \\nMìn...</td>\n",
       "      <td>áo rộng mình kg</td>\n",
       "      <td>👍</td>\n",
       "      <td>0</td>\n",
       "      <td>thumbsup thumbsup thumbsup thumbsup thumbsup t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Khá buồn . Đặt 2 cái đều không chạy ...</td>\n",
       "      <td>khá buồn đặt cái đều không chạy giơ...</td>\n",
       "      <td>♀️ 🤷</td>\n",
       "      <td>0</td>\n",
       "      <td>female_sign shrug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14184</th>\n",
       "      <td>Không mua hối hận đừng kêu nhá haha, ...</td>\n",
       "      <td>không mua hối hận đừng kêu nhá hàng ...</td>\n",
       "      <td>😂</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14186</th>\n",
       "      <td>khuyên xinh lắm lúc mình đặt còn đươ...</td>\n",
       "      <td>khuyên xinh lắm lúc đặt còn được dea...</td>\n",
       "      <td>😘</td>\n",
       "      <td>1</td>\n",
       "      <td>kissing_heart kissing_heart kissing_heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14193</th>\n",
       "      <td>đẹp rẻ chất lượng vô cùng xịn 😗😗😗 ma...</td>\n",
       "      <td>đẹp rẻ chất lượng vô cùng xịn mãi u...</td>\n",
       "      <td>😗</td>\n",
       "      <td>1</td>\n",
       "      <td>kissing kissing kissing kissing kissing kissin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14194</th>\n",
       "      <td>Đẹp, sẽ ủng hộ tiếp nhé 👕👕👕👕👕👕👕👕👕👕👕👕👕👕...</td>\n",
       "      <td>đẹp sẽ ủng hộ tiếp nhé</td>\n",
       "      <td>👕</td>\n",
       "      <td>1</td>\n",
       "      <td>tshirt tshirt tshirt tshirt tshirt tshirt tshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14200</th>\n",
       "      <td>Mua về cho chồng mà để con em nó mặc...</td>\n",
       "      <td>mua về cho chồng mà con em mặc thử tr...</td>\n",
       "      <td>😂</td>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             raw_comment  ...                                       decode_emoji\n",
       "4      Mình mua 2 cái, một dùng ok. Một cái k...  ...                                                cry\n",
       "15     Giao sai màu sai size có 1 dép lông size 3...  ...             cursing_face cursing_face cursing_face\n",
       "30     Đơn hàng đã thanh toán airpay rồi mà sh...  ...                                          roll_eyes\n",
       "43     Áo croptop freesize rộng với mình \\nMìn...  ...  thumbsup thumbsup thumbsup thumbsup thumbsup t...\n",
       "47     Khá buồn . Đặt 2 cái đều không chạy ...  ...                                  female_sign shrug\n",
       "...                                                  ...  ...                                                ...\n",
       "14184  Không mua hối hận đừng kêu nhá haha, ...  ...                                                joy\n",
       "14186  khuyên xinh lắm lúc mình đặt còn đươ...  ...          kissing_heart kissing_heart kissing_heart\n",
       "14193  đẹp rẻ chất lượng vô cùng xịn 😗😗😗 ma...  ...  kissing kissing kissing kissing kissing kissin...\n",
       "14194  Đẹp, sẽ ủng hộ tiếp nhé 👕👕👕👕👕👕👕👕👕👕👕👕👕👕...  ...  tshirt tshirt tshirt tshirt tshirt tshirt tshi...\n",
       "14200  Mua về cho chồng mà để con em nó mặc...  ...                                                joy\n",
       "\n",
       "[1283 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bước này, ta thực hiện chia `emojis` ra thành hai tập training data và test data với test data chiếm 20% số lượng các observer của `emojis`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['decode_emoji'], data['label'], test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1521                                            heart_eyes\n",
       "11485    hearts hearts hearts kissing_heart kissing_hea...\n",
       "3467                                              relieved\n",
       "7740     persevere persevere persevere persevere persev...\n",
       "12870                                          heart heart\n",
       "                               ...                        \n",
       "12351                                           gift_heart\n",
       "12799                                                heart\n",
       "13056                                            wink hugs\n",
       "10730    blush blush blush blush blush blush blush blus...\n",
       "13032                                                 wink\n",
       "Name: decode_emoji, Length: 1026, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bây giờ, chúng ta thực hiện kĩ thuật **vectorizing text**, ta áp dụng lần lượt hai phương pháp là **Bag of Words** và **TF-IDF**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Bag of words\n",
    "bow_vec = CountVectorizer()\n",
    "bow_emojis = bow_vec.fit_transform(X_train)\n",
    "\n",
    "print(bow_vec.get_feature_names())\n",
    "print(bow_emojis.toarray())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['100', 'anger', 'angry', 'ballet_shoes', 'bangbang', 'birthday', 'blossom', 'blue_heart', 'blush', 'bouquet', 'bow', 'broken_heart', 'butterfly', 'cake', 'camera', 'carrot', 'cherry_blossom', 'clap', 'cloud_with_rain', 'clown_face', 'cold_face', 'cold_sweat', 'compass', 'confounded', 'confused', 'cow', 'crossed_fingers', 'cry', 'crying_cat_face', 'cursing_face', 'disappointed', 'disappointed_relieved', 'dizzy', 'dizzy_face', 'dog', 'dog2', 'dollar', 'eagle', 'expressionless', 'face_with_thermometer', 'facepalm', 'fallen_leaf', 'fearful', 'female_sign', 'fire', 'fist_left', 'floppy_disk', 'flushed', 'four_leaf_clover', 'free', 'frowning_face', 'fu', 'ghost', 'gift_heart', 'golf', 'green_heart', 'green_salad', 'grimacing', 'grin', 'grinning', 'haircut', 'hand_over_mouth', 'hatched_chick', 'heart', 'heart_eyes', 'heart_eyes_cat', 'heartbeat', 'heartpulse', 'hearts', 'heavy_check_mark', 'heavy_heart_exclamation', 'hibiscus', 'high_brightness', 'hugs', 'information_desk_person', 'innocent', 'joy', 'joy_cat', 'kiss', 'kissing', 'kissing_cat', 'kissing_closed_eyes', 'kissing_heart', 'kissing_smiling_eyes', 'knife', 'lobster', 'lollipop', 'loud_sound', 'male_sign', 'man_facepalming', 'mask', 'moneybag', 'musical_score', 'nauseated_face', 'nerd_face', 'neutral_face', 'no_good', 'no_mouth', 'octopus', 'ok_hand', 'ok_man', 'ok_person', 'ok_woman', 'older_man', 'open_mouth', 'partying_face', 'pensive', 'persevere', 'pig_nose', 'pleading_face', 'point_left', 'point_right', 'potted_plant', 'pout', 'pray', 'purple_heart', 'pushpin', 'raised_eyebrow', 'raising_hand_woman', 'red_circle', 'relaxed', 'relieved', 'revolving_hearts', 'ribbon', 'rice', 'rice_ball', 'rofl', 'roll_eyes', 'satisfied', 'scream', 'see_no_evil', 'shamrock', 'shit', 'shrug', 'skull_and_crossbones', 'sleeping', 'sleepy', 'slightly_frowning_face', 'slightly_smiling_face', 'smile', 'smiley', 'smiley_cat', 'smiling_face_with_tear', 'smiling_face_with_three_hearts', 'smiling_imp', 'smirk', 'sneezing_face', 'sob', 'soon', 'sos', 'spaghetti', 'sparkles', 'sparkling_heart', 'speak_no_evil', 'squid', 'star', 'star2', 'star_struck', 'strawberry', 'stuck_out_tongue', 'stuck_out_tongue_closed_eyes', 'stuck_out_tongue_winking_eye', 'sun_behind_rain_cloud', 'sun_with_face', 'sunglasses', 'sweat', 'sweat_drops', 'sweat_smile', 'tada', 'telephone_receiver', 'thinking', 'thumbsdown', 'thumbsup', 'tired_face', 'triumph', 'tshirt', 'two_hearts', 'unamused', 'upside_down_face', 'vietnam', 'vomiting_face', 'walking', 'wave', 'weary', 'white_check_mark', 'white_heart', 'wink', 'woman_facepalming', 'woman_shrugging', 'woozy_face', 'worried', 'yellow_heart', 'yum', 'zany_face', 'zipper_mouth_face']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_emojis = tfidf_vec.fit_transform(X_train)\n",
    "\n",
    "print(tfidf_emojis.toarray())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}